{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of classification_of_pets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z3FGtKHYcc5k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, LeakyReLU, BatchNormalization\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Input \n",
        "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization, Concatenate, Reshape\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from random import shuffle\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xvzf images.tar.gz && tar -xvzf annotations.tar.gz\n",
        "!rm  images/*.mat"
      ],
      "metadata": {
        "id": "qXHY4ArpcvnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08fe645-bd07-4652-d174-accd83b61761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-22 05:20:25--  http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz [following]\n",
            "--2021-12-22 05:20:25--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "_kZqPuazdSXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "WnPaCi8TsW9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "if len(physical_devices) > 0:\n",
        "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "physical_devices"
      ],
      "metadata": {
        "id": "KaYU5iVqsY1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBB(file):\n",
        "  \n",
        "  #parse the annotations\n",
        "  path = f'annotations/xmls/{file}'\n",
        "  tree = ET.parse(path)\n",
        "  root = tree.getroot()\n",
        "  \n",
        "  ob = root.find('object')\n",
        "  bndbox = ob.find('bndbox')\n",
        "  xmin = bndbox.find('xmin').text\n",
        "  xmax = bndbox.find('xmax').text\n",
        "\n",
        "  ymin = bndbox.find('ymin').text\n",
        "  ymax = bndbox.find('ymax').text\n",
        "\n",
        "  return((int(xmin), int(ymin)), (int(xmax), int(ymax)))\n",
        "\n",
        "def drawBB(file):\n",
        "  #draw the bounding box\n",
        "  img_path = f'images/{file[:-4]}.jpg'\n",
        "  img = cv2.imread(img_path)\n",
        "  \n",
        "  (xmin, ymin), (xmax, ymax) = getBB(file)\n",
        "\n",
        "  print(getBB(file))\n",
        "  annotated = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n",
        "  \n",
        "  plt.imshow(annotated[:,:,::-1])\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eZphEEzT7znv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = np.random.choice(os.listdir('annotations/xmls/'))\n",
        "drawBB(file)"
      ],
      "metadata": {
        "id": "8Z5MRh-H7_ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_generator(files, batch_size = 32, sz = (256, 256)):\n",
        "  \n",
        "  while True: \n",
        "    \n",
        "    #extract a random batch \n",
        "    batch = np.random.choice(files, size = batch_size)    \n",
        "    \n",
        "    #variables for collecting batches of inputs and outputs \n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    \n",
        "    \n",
        "    for f in batch:\n",
        "        img_path = f'images/{f[:-4]}.jpg'\n",
        "        img = Image.open(img_path)\n",
        "        w,h = img.size\n",
        "        \n",
        "        img = img.resize(sz)\n",
        "        (xmin, ymin), (xmax, ymax) = getBB(f)\n",
        "        \n",
        "        img = np.array(img).astype('float32')\n",
        "        if len(img.shape) == 2:\n",
        "          img = np.stack((img,)*3, axis=-1)\n",
        "\n",
        "        else:\n",
        "          img = img[:,:,0:3]\n",
        "        \n",
        "        box = np.array([xmin/w, ymin/h, xmax/w, ymax/h])\n",
        "\n",
        "        batch_x.append(img/255)\n",
        "        batch_y.append(box)\n",
        "\n",
        "    #preprocess a batch of images and masks \n",
        "    batch_x = np.array(batch_x)\n",
        "    batch_y = np.array(batch_y)\n",
        "\n",
        "    yield (batch_x, batch_y)      "
      ],
      "metadata": {
        "id": "4fd-77IJ8Y2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/images\"\n",
        "TB_LOGS = \"tensorboard_logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "IMAGE_SIZE = (256, 256)\n",
        "RANDOM_STATE = 7\n",
        "TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 0.8, 0.1, 0.1"
      ],
      "metadata": {
        "id": "AJu8TfvtscYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 35\n",
        "LEARNING_RATE = 0.0001\n",
        "PLOTS_DPI = 200"
      ],
      "metadata": {
        "id": "NG0PmOQLsjtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageNames = [os.path.basename(file) for file in glob.glob(os.path.join(BASE_PATH, '*.jpg'))]\n",
        "\n",
        "print(f\"\\nTotal number of image files: {len(imageNames)}\")"
      ],
      "metadata": {
        "id": "Vv00SqpEsmOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [' '.join(name.split('_')[:-1]) for name in imageNames ]\n",
        "\n",
        "print(f\"\\nTotal number of unique labels: {len(np.unique(labels))}\")"
      ],
      "metadata": {
        "id": "TuTwjdu5tnM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncDict = {name : ind for ind, name in enumerate(np.unique(labels))}\n",
        "for k, v in labelEncDict.items():\n",
        "    print(f\"{k:32} : {v}\")"
      ],
      "metadata": {
        "id": "iyEzjqWLtqzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelDecDict = {ind: name for name, ind in labelEncDict.items()}\n",
        "for k, v in labelDecDict.items():\n",
        "    print(f\"{k:3} : {v}\")"
      ],
      "metadata": {
        "id": "1JKTohVrts51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in labelEncDict.keys():\n",
        "    print(f\"{i:32} : {labels.count(i)}\")"
      ],
      "metadata": {
        "id": "-d8vUBrmtwFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "imageData = []\n",
        "\n",
        "for name in tqdm(imageNames, desc = 'Loading image data', unit = ' images'):\n",
        "    img = load_img(os.path.join(BASE_PATH, name))\n",
        "    img = tf.image.resize_with_pad(img_to_array(img, dtype = 'uint8'), *IMAGE_SIZE).numpy().astype('uint8')\n",
        "    imageData.append(img)\n",
        "    \n",
        "imageData = np.array(imageData)\n",
        "imageData.shape"
      ],
      "metadata": {
        "id": "Msq8ejf3t_E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelsEncoded = list(map(lambda x : labelEncDict.get(x), labels))\n",
        "\n",
        "for i, l in zip(imageNames[::1000], labelsEncoded[::1000]):\n",
        "    print(f\"{i:32}\\t{labelDecDict[l]:32}\\t{l}\")"
      ],
      "metadata": {
        "id": "q9mVKbOouVft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(nrows = 3, ncols = 3, figsize = (15, 15))\n",
        "\n",
        "for i, imgIndex in enumerate(np.random.randint(0, len(imageNames), size = 9)):\n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  plt.axis(False)\n",
        "  plt.grid(False)\n",
        "  plt.title(f'{imageNames[imgIndex]}\\n{labels[imgIndex]}\\n{labelsEncoded[imgIndex]}')\n",
        "  plt.imshow(imageData[imgIndex])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hzRRdCPiuYQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageData.max()"
      ],
      "metadata": {
        "id": "7ZMfnYwNuf5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tv, X_test, y_tv, y_test = train_test_split(\n",
        "    imageData, \n",
        "    labelsEncoded, \n",
        "    test_size = TEST_SIZE, \n",
        "    random_state = RANDOM_STATE, \n",
        "    stratify = labelsEncoded\n",
        "    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_tv, \n",
        "    y_tv, \n",
        "    test_size = VAL_SIZE, \n",
        "    random_state = RANDOM_STATE, \n",
        "    stratify = y_tv\n",
        "    )\n",
        "\n",
        "print(f'Training Data: {X_train.shape}')\n",
        "print(f'Training Labels: {len(y_train)}')\n",
        "print(f'\\nValidation Data: {X_val.shape}')\n",
        "print(f'Validation Labels: {len(y_val)}')\n",
        "print(f'\\nTesting Data: {X_test.shape}')\n",
        "print(f'Testing Labels: {len(y_test)}')"
      ],
      "metadata": {
        "id": "1xElkbeNulB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del imageData\n",
        "del labelsEncoded\n",
        "del X_tv\n",
        "del y_tv"
      ],
      "metadata": {
        "id": "poFlRsmSupk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                               rotation_range = 30,\n",
        "                               width_shift_range = 0.1,\n",
        "                               height_shift_range = 0.1,\n",
        "                               shear_range = 0.1,\n",
        "                               zoom_range = 0.1,\n",
        "                               horizontal_flip = True,\n",
        "                               fill_mode = 'nearest')\n",
        "train_data = train_gen.flow(x = X_train, y = y_train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "len(train_data)"
      ],
      "metadata": {
        "id": "89hlZaoZutM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = ImageDataGenerator(rescale = 1./255)\n",
        "val_data = val_gen.flow(x = X_val, y = y_val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "len(val_data)"
      ],
      "metadata": {
        "id": "6DwADA3AuwSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "test_data = test_gen.flow(x = X_test, y = y_test, batch_size = BATCH_SIZE)\n",
        "len(test_data)"
      ],
      "metadata": {
        "id": "eckJ535hu9LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generator_images(gen, suptitle, labelDecDict, print_pred = False, model = None, nrows = 3, ncols = 3, figsize = (12, 12)):\n",
        "    gen_data = gen.next()\n",
        "    \n",
        "    plt.subplots(nrows = nrows, ncols = ncols, figsize = figsize)\n",
        "    plt.suptitle(suptitle, fontsize = 20)\n",
        "    plt.tight_layout(rect = [0, 0, 1, 0.96], h_pad = 2)\n",
        "    \n",
        "    if(print_pred and model):\n",
        "        pred = np.argmax(model.predict(gen_data[0]), axis=1)\n",
        "\n",
        "    for i in range(nrows * ncols):\n",
        "        plt.subplot(nrows, ncols, i + 1)\n",
        "        plt.axis(False)\n",
        "        plt.grid(False)\n",
        "        \n",
        "        if(print_pred and pred.any()):\n",
        "            plt.title(f\"True: {labelDecDict[gen_data[1][i]]}\\nPredicted: {labelDecDict[pred[i]]}\")\n",
        "        else:\n",
        "            plt.title(labelDecDict[gen_data[1][i]])\n",
        "        plt.imshow(gen_data[0][i])"
      ],
      "metadata": {
        "id": "6tdEeeN3vB_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_generator_images(train_data, \"Training data\", labelDecDict)"
      ],
      "metadata": {
        "id": "cfuoe-NKvDkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_generator_images(val_data, \"Validation data\", labelDecDict)"
      ],
      "metadata": {
        "id": "QxBZfmtYvJBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, 5, padding = 'same', input_shape = (*IMAGE_SIZE, 3)),\n",
        "    Conv2D(32, 5, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 4, padding = 'same'),\n",
        "    Conv2D(32, 4, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(64, 4, padding = 'same'),\n",
        "    Conv2D(64, 4, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, 3, padding = 'same'),\n",
        "    Conv2D(64, 3, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(128, 3, padding = 'same'),\n",
        "    Conv2D(128, 3, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 2, padding = 'same'),\n",
        "    Conv2D(128, 2, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(256, 2, padding = 'same'),\n",
        "    Conv2D(256, 2, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    \n",
        "    Flatten(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation = 'sigmoid'),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation = 'sigmoid'),\n",
        "    Dropout(0.1),\n",
        "    Dense(len(labelEncDict), activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(LEARNING_RATE), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['sparse_categorical_accuracy'])\n",
        " \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gotRTwVKvLwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "earlyStop = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
        "tensorBoard = TensorBoard(log_dir = TB_LOGS, histogram_freq = 20)\n",
        "\n",
        "history = model.fit(train_data, validation_data = val_data, epochs = EPOCHS, verbose = 1, callbacks = [earlyStop, tensorBoard])"
      ],
      "metadata": {
        "id": "5rNZL01avSF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['sparse_categorical_accuracy']\n",
        "val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = history.epoch\n",
        "\n",
        "plt.figure(figsize = (16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('plots/acc_and_loss.jpg', dpi = PLOTS_DPI, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_tlhI7k4kCNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_data, verbose = 0)\n",
        "\n",
        "print(f\"Loss on Testing data: {test_loss}\")\n",
        "print(f\"Accuracy on Testing data: {test_acc}\")"
      ],
      "metadata": {
        "id": "0eUOMWb-kWC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_generator_images(test_data, \"Testing data\", labelDecDict, print_pred = True, model = model)"
      ],
      "metadata": {
        "id": "dt16xn6vkqA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kHsRVfWumHJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(model.predict(X_test/255), axis = 1)\n",
        "\n",
        "_, ax = plt.subplots(figsize = (20, 16))\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred, labels = list(labelEncDict.values())),\n",
        "                        display_labels = list(labelEncDict.keys())\n",
        "                        ).plot(ax = ax, xticks_rotation = 'vertical')\n",
        "                        \n",
        "plt.savefig('plots/confusion_matrix.jpg', dpi = PLOTS_DPI, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "pzwSb9Ankxda",
        "outputId": "804f70fc-c449-4ea3-f296-c15c11e13dd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-79aa82f7c7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred, labels = list(labelEncDict.values())),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('models/pet_image_classifier.h5')"
      ],
      "metadata": {
        "id": "T2Q43sfqmIoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = tf.keras.models.load_model('models/pet_image_classifier.h5')\n",
        "\n",
        "sm_test_loss, sm_test_acc = saved_model.evaluate(test_data, verbose = 0)\n",
        "\n",
        "print(f\"Loss on Testing data: {sm_test_loss}\")\n",
        "print(f\"Accuracy on Testing data: {sm_test_acc}\")"
      ],
      "metadata": {
        "id": "QYjJJRc_k-Bf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}